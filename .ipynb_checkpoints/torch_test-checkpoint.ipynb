{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a0d25b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pywt\n",
    "import torchsummary\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2359e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e57a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickler(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "    return a\n",
    "\n",
    "path = \"pickled/\"\n",
    "train_readings = unpickler(path + 'train_readings.pkl')\n",
    "train_diagnostic = unpickler(path + 'train_diagnostic.pkl').astype('float32')\n",
    "validate_readings = unpickler(path + 'validate_readings.pkl')\n",
    "validate_diagnostic = unpickler(path + 'validate_diagnostic.pkl').astype('float32')\n",
    "test_readings = unpickler(path + 'test_readings.pkl')\n",
    "test_diagnostic = unpickler(path + 'test_diagnostic.pkl').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2864058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, readings, labels, cwt=False, scales=[], wavelet=''):\n",
    "        self.readings = readings # should i convert to torch.tensor here?\n",
    "        self.labels = labels\n",
    "        self.scales = scales\n",
    "        self.wavelet = wavelet\n",
    "        if cwt:\n",
    "            self.apply_cwt()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.readings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.readings[idx], self.labels[idx]\n",
    "    \n",
    "    def apply_cwt(self):\n",
    "        cwt = lambda x : pywt.cwt(x, self.scales, self.wavelet)[0] #pytorch uses channels first, unlike tensorflow's default\n",
    "        self.readings = np.array([cwt(i) for i in self.readings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4479b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scales = 20\n",
    "scales = np.linspace(0.1, 4, total_scales) # 32 evenly spaced numbers between 0.1 and 4\n",
    "wavelet = 'mexh'\n",
    "batch_size = 64\n",
    "kernel_size = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462bdcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how to increase efficiency?\n",
    "\n",
    "train_dataloader = DataLoader(ECG(train_readings, \n",
    "                                  train_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)\n",
    "validate_dataloader = DataLoader(ECG(validate_readings, \n",
    "                                  validate_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(ECG(test_readings, \n",
    "                                  test_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ce9b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 20, 1000])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "01d81daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best way to adjust hyperparameters\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Conv1d(in_channels=total_scales, out_channels=32, kernel_size=kernel_size, padding='same')) \n",
    "        modules.append(\n",
    "            nn.BatchNorm1d(num_features=32))\n",
    "        modules.append(\n",
    "            nn.Dropout(0.2)) # 20 percent of the inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool1d(kernel_size=kernel_size * 2))  \n",
    "        \n",
    "        modules.append(\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=6, padding='same')) \n",
    "        modules.append(\n",
    "            nn.BatchNorm1d(num_features=32))\n",
    "        modules.append(\n",
    "            nn.Dropout(0.2)) # 20 percent of the inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool1d(kernel_size=4)) \n",
    "        \n",
    "        modules.append(nn.Flatten())\n",
    "        modules.append(nn.Linear(96, 256)) # dense layer with 50 neurons \n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.Linear(256, 2))\n",
    "        modules.append(\n",
    "            nn.LogSoftmax(dim=1))\n",
    "    \n",
    "        \n",
    "    \n",
    "        self.network = nn.Sequential(*modules) # unpack the modules\n",
    "    \n",
    "    def summary(self):\n",
    "        return torchsummary.summary(self, input_size=(total_scales, 1000))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        prob = self.network(x)\n",
    "        return prob\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bb6bd7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 1000]          26,272\n",
      "       BatchNorm1d-2             [-1, 32, 1000]              64\n",
      "           Dropout-3             [-1, 32, 1000]               0\n",
      "              ReLU-4             [-1, 32, 1000]               0\n",
      "         MaxPool1d-5               [-1, 32, 12]               0\n",
      "            Conv1d-6               [-1, 32, 12]           6,176\n",
      "       BatchNorm1d-7               [-1, 32, 12]              64\n",
      "           Dropout-8               [-1, 32, 12]               0\n",
      "              ReLU-9               [-1, 32, 12]               0\n",
      "        MaxPool1d-10                [-1, 32, 3]               0\n",
      "          Flatten-11                   [-1, 96]               0\n",
      "           Linear-12                  [-1, 256]          24,832\n",
      "             ReLU-13                  [-1, 256]               0\n",
      "           Linear-14                    [-1, 2]             514\n",
      "       LogSoftmax-15                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 57,922\n",
      "Trainable params: 57,922\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.08\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 0.22\n",
      "Estimated Total Size (MB): 1.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "46231b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-5\n",
    "def precision(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 1:\n",
    "            if y_true[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    \n",
    "    return tp / (tp + fp + EPS)\n",
    "\n",
    "def recall(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    return tp / (tp + fn + EPS)\n",
    "        \n",
    "\n",
    "def f1(_precision, _recall):\n",
    "    return (2 * _precision * _recall) / (_precision + _recall + EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8573af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_diagnostic),\n",
    "                                        y = train_diagnostic                                                    \n",
    "                                    )\n",
    "class_weights = torch.ceil(torch.from_numpy(class_weights)).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6403f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.NLLLoss(weight=class_weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ccef777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.path.join(os.getcwd(), 'torch_check')\n",
    "def get_max_f1():\n",
    "    max_f1_score = open(os.path.join(current_directory, 'max_f1.txt'), 'r').readline().strip(\"\\n\")\n",
    "    return float(max_f1_score)\n",
    "\n",
    "def get_max_accuracy():\n",
    "    max_accuracy = open(os.path.join(current_directory, 'max_f1.txt'), 'r').readline().strip(\"\\n\")\n",
    "    return float(max_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bd58a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.type(torch.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        X, y = X.to(device), y.to(device)\n",
    "    \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "963e8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    total_true = torch.empty(0).to(device)\n",
    "    total_pred = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.type(torch.FloatTensor)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).to(device)\n",
    "            \n",
    "            round_pred = torch.argmax(pred, dim=1)\n",
    "            \n",
    "            total_true = torch.cat((total_true, y))\n",
    "            \n",
    "            total_pred = torch.cat((total_pred, round_pred))\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (round_pred == y).type(torch.float).sum().item()\n",
    "        \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    precision_ = precision(total_pred, total_true)\n",
    "    recall_ = recall(total_pred, total_true)\n",
    "    f1_ = f1(precision_, recall_)\n",
    "    print(f\"Precision: {precision_}\")\n",
    "    print(f\"Recall: {recall_}\")\n",
    "    print(f\"F1 Score: {f1_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a6812d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.475975  [    0/10977]\n",
      "loss: 0.178501  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.173869 \n",
      "\n",
      "Precision: 0.47376960262969386\n",
      "Recall: 0.9722530413734402\n",
      "F1 Score: 0.637086498672443\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.178847  [    0/10977]\n",
      "loss: 0.095102  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 79.6%, Avg loss: 0.321097 \n",
      "\n",
      "Precision: 0.285943516412248\n",
      "Recall: 0.9889012098901087\n",
      "F1 Score: 0.443611155853753\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.145855  [    0/10977]\n",
      "loss: 0.097671  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.225271 \n",
      "\n",
      "Precision: 0.3671198995998356\n",
      "Recall: 0.9889012098901087\n",
      "F1 Score: 0.5354527788460074\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.190881  [    0/10977]\n",
      "loss: 0.077316  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.171401 \n",
      "\n",
      "Precision: 0.6184407749742071\n",
      "Recall: 0.9156492684167673\n",
      "F1 Score: 0.7382502146503269\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.261054  [    0/10977]\n",
      "loss: 0.120684  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.255160 \n",
      "\n",
      "Precision: 0.3481748882945251\n",
      "Recall: 0.9633740181645504\n",
      "F1 Score: 0.5114869633509004\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.198210  [    0/10977]\n",
      "loss: 0.113948  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.198072 \n",
      "\n",
      "Precision: 0.41643323801851895\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.5862593834688168\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.110462  [    0/10977]\n",
      "loss: 0.128053  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.159580 \n",
      "\n",
      "Precision: 0.6454615931306316\n",
      "Recall: 0.9234184137245459\n",
      "F1 Score: 0.7598125016342526\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.084175  [    0/10977]\n",
      "loss: 0.094078  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.7%, Avg loss: 0.212032 \n",
      "\n",
      "Precision: 0.399999998206278\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.5697819081017828\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.114848  [    0/10977]\n",
      "loss: 0.201463  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.162405 \n",
      "\n",
      "Precision: 0.4715878891577914\n",
      "Recall: 0.9855715761867749\n",
      "F1 Score: 0.6379266520218148\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.102040  [    0/10977]\n",
      "loss: 0.199194  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.219139 \n",
      "\n",
      "Precision: 0.377899618819487\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.5476732674970555\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.114695  [    0/10977]\n",
      "loss: 0.232256  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.191982 \n",
      "\n",
      "Precision: 0.5248091569668629\n",
      "Recall: 0.9156492684167673\n",
      "F1 Score: 0.6672011856242516\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.143385  [    0/10977]\n",
      "loss: 0.240627  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.165056 \n",
      "\n",
      "Precision: 0.48598130573952003\n",
      "Recall: 0.98113206458233\n",
      "F1 Score: 0.6499955647820282\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.123566  [    0/10977]\n",
      "loss: 0.075715  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.199253 \n",
      "\n",
      "Precision: 0.41320406088086764\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.5836280607097283\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.062965  [    0/10977]\n",
      "loss: 0.103827  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.129518 \n",
      "\n",
      "Precision: 0.581134560810458\n",
      "Recall: 0.9778024308789963\n",
      "F1 Score: 0.728998213868015\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.151547  [    0/10977]\n",
      "loss: 0.131166  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 83.8%, Avg loss: 0.255599 \n",
      "\n",
      "Precision: 0.33595211247305606\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.502514413224816\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.103429  [    0/10977]\n",
      "loss: 0.099913  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.1%, Avg loss: 0.172384 \n",
      "\n",
      "Precision: 0.45318929808030195\n",
      "Recall: 0.9778024308789963\n",
      "F1 Score: 0.6193278293710142\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.139432  [    0/10977]\n",
      "loss: 0.233001  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 74.1%, Avg loss: 0.413556 \n",
      "\n",
      "Precision: 0.24025627271688127\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.38734354771713625\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.100267  [    0/10977]\n",
      "loss: 0.259275  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.166777 \n",
      "\n",
      "Precision: 0.4725158537393454\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.6401674831332705\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.072577  [    0/10977]\n",
      "loss: 0.208770  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.3%, Avg loss: 0.212708 \n",
      "\n",
      "Precision: 0.3916483499268204\n",
      "Recall: 0.9889012098901087\n",
      "F1 Score: 0.561079055720647\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.087203  [    0/10977]\n",
      "loss: 0.125407  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.229680 \n",
      "\n",
      "Precision: 0.5562632657023123\n",
      "Recall: 0.8723640302734292\n",
      "F1 Score: 0.6793383677271273\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.167404  [    0/10977]\n",
      "loss: 0.099576  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.281563 \n",
      "\n",
      "Precision: 0.32806178621529314\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.49281393793775685\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.261679  [    0/10977]\n",
      "loss: 0.081768  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.185991 \n",
      "\n",
      "Precision: 0.42891450322327324\n",
      "Recall: 0.9911209656923311\n",
      "F1 Score: 0.5987218943893715\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.075629  [    0/10977]\n",
      "loss: 0.138254  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.5%, Avg loss: 0.196305 \n",
      "\n",
      "Precision: 0.4166279590495682\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.5874221626242399\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.285503  [    0/10977]\n",
      "loss: 0.232164  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.191127 \n",
      "\n",
      "Precision: 0.48176470304844293\n",
      "Recall: 0.9089900010100999\n",
      "F1 Score: 0.6297532524843266\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.088756  [    0/10977]\n",
      "loss: 0.051764  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.199563 \n",
      "\n",
      "Precision: 0.39831634737121685\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.5693436066941785\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.036755  [    0/10977]\n",
      "loss: 0.148075  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.9%, Avg loss: 0.193008 \n",
      "\n",
      "Precision: 0.42425672286806637\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.5953600477970723\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.117891  [    0/10977]\n",
      "loss: 0.539822  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.172521 \n",
      "\n",
      "Precision: 0.4680851038931643\n",
      "Recall: 0.9766925529778852\n",
      "F1 Score: 0.6328614906946664\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.204449  [    0/10977]\n",
      "loss: 0.262395  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.228212 \n",
      "\n",
      "Precision: 0.3680327853769148\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.5375596614708089\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.037289  [    0/10977]\n",
      "loss: 0.112581  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.133513 \n",
      "\n",
      "Precision: 0.5232763669812824\n",
      "Recall: 0.9855715761867749\n",
      "F1 Score: 0.6835982355027971\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.118287  [    0/10977]\n",
      "loss: 0.087755  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.348176 \n",
      "\n",
      "Precision: 0.2734208108836716\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.4289099707055581\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.120344  [    0/10977]\n",
      "loss: 0.083584  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.238873 \n",
      "\n",
      "Precision: 0.35756853254839677\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.5266198711870809\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.054900  [    0/10977]\n",
      "loss: 0.114255  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.148020 \n",
      "\n",
      "Precision: 0.5011273928910519\n",
      "Recall: 0.9866814540878862\n",
      "F1 Score: 0.6646684247951513\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.137193  [    0/10977]\n",
      "loss: 0.119998  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.268944 \n",
      "\n",
      "Precision: 0.35711438677913754\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.5255093052445681\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.089469  [    0/10977]\n",
      "loss: 0.403262  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.241003 \n",
      "\n",
      "Precision: 0.3463170059918357\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.5140202108322549\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.066006  [    0/10977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.081863  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.9%, Avg loss: 0.147203 \n",
      "\n",
      "Precision: 0.504788729550486\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.6696517316736275\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.303272  [    0/10977]\n",
      "loss: 0.240099  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.216542 \n",
      "\n",
      "Precision: 0.38326931121097174\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.55363346916149\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.076769  [    0/10977]\n",
      "loss: 0.044099  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.180421 \n",
      "\n",
      "Precision: 0.42877628858137523\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.5993943844853463\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.104977  [    0/10977]\n",
      "loss: 0.240027  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.483073 \n",
      "\n",
      "Precision: 0.22277350478101338\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.36414948597171604\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.080950  [    0/10977]\n",
      "loss: 0.135561  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Avg loss: 0.204604 \n",
      "\n",
      "Precision: 0.5733522283958028\n",
      "Recall: 0.8978912219989875\n",
      "F1 Score: 0.699822226893685\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.131913  [    0/10977]\n",
      "loss: 0.064791  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.9%, Avg loss: 0.172769 \n",
      "\n",
      "Precision: 0.4482931704402953\n",
      "Recall: 0.9911209656923311\n",
      "F1 Score: 0.6173479363682476\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.050435  [    0/10977]\n",
      "loss: 0.052190  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.119763 \n",
      "\n",
      "Precision: 0.5878423474426029\n",
      "Recall: 0.9766925529778852\n",
      "F1 Score: 0.7339402568988876\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.427460  [    0/10977]\n",
      "loss: 0.103915  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 82.5%, Avg loss: 0.286040 \n",
      "\n",
      "Precision: 0.3192321353742192\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.4835719822306357\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.128677  [    0/10977]\n",
      "loss: 0.099354  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Avg loss: 0.149100 \n",
      "\n",
      "Precision: 0.48331539029431975\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.650956089819086\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.093486  [    0/10977]\n",
      "loss: 0.113638  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.168009 \n",
      "\n",
      "Precision: 0.4501253110269408\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6201614551253295\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.153977  [    0/10977]\n",
      "loss: 0.141585  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.150850 \n",
      "\n",
      "Precision: 0.49391592647170396\n",
      "Recall: 0.9911209656923311\n",
      "F1 Score: 0.6592794242370431\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.103700  [    0/10977]\n",
      "loss: 0.054521  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.6%, Avg loss: 0.154097 \n",
      "\n",
      "Precision: 0.493936050198809\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.6600323930011035\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.107131  [    0/10977]\n",
      "loss: 0.113466  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.128562 \n",
      "\n",
      "Precision: 0.7065309524467265\n",
      "Recall: 0.9245282916256572\n",
      "F1 Score: 0.8009566201068437\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.087382  [    0/10977]\n",
      "loss: 0.072671  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.7%, Avg loss: 0.129754 \n",
      "\n",
      "Precision: 0.5304553487258702\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.6921250887851199\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.119096  [    0/10977]\n",
      "loss: 0.132281  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.7%, Avg loss: 0.224221 \n",
      "\n",
      "Precision: 0.38170212603531006\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.5518261960072992\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.043321  [    0/10977]\n",
      "loss: 0.208003  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 78.9%, Avg loss: 0.356909 \n",
      "\n",
      "Precision: 0.27985074539847404\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.4372081406409837\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.114581  [    0/10977]\n",
      "loss: 0.133003  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.138122 \n",
      "\n",
      "Precision: 0.5485466880114614\n",
      "Recall: 0.9844616982856638\n",
      "F1 Score: 0.704522801416778\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.065663  [    0/10977]\n",
      "loss: 0.182417  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.138541 \n",
      "\n",
      "Precision: 0.5082527005790968\n",
      "Recall: 0.9911209656923311\n",
      "F1 Score: 0.6719292983447765\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.192689  [    0/10977]\n",
      "loss: 0.060114  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 0.897315 \n",
      "\n",
      "Precision: 0.17414860647417066\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.29658669458510845\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.083251  [    0/10977]\n",
      "loss: 0.024591  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.180357 \n",
      "\n",
      "Precision: 0.4377788773536\n",
      "Recall: 0.9800221866812189\n",
      "F1 Score: 0.6052047745289536\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.034605  [    0/10977]\n",
      "loss: 0.041680  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.135478 \n",
      "\n",
      "Precision: 0.5114678869755281\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.6744756540534449\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.275815  [    0/10977]\n",
      "loss: 0.019564  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.1%, Avg loss: 0.218301 \n",
      "\n",
      "Precision: 0.4086363617789256\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.5798088372239483\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.012373  [    0/10977]\n",
      "loss: 0.087876  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.349775 \n",
      "\n",
      "Precision: 0.3012411932195867\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.4626445526117883\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.365450  [    0/10977]\n",
      "loss: 0.136704  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.151402 \n",
      "\n",
      "Precision: 0.5113438015628633\n",
      "Recall: 0.9755826750767739\n",
      "F1 Score: 0.6709878487075743\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.218814  [    0/10977]\n",
      "loss: 0.068675  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.8%, Avg loss: 0.109124 \n",
      "\n",
      "Precision: 0.6131237141960102\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.7588785249240321\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.156509  [    0/10977]\n",
      "loss: 0.051173  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.114742 \n",
      "\n",
      "Precision: 0.6233859352698283\n",
      "Recall: 0.9644838960656615\n",
      "F1 Score: 0.7572936991030377\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.258989  [    0/10977]\n",
      "loss: 0.125123  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.173970 \n",
      "\n",
      "Precision: 0.6521739077924806\n",
      "Recall: 0.8990010999000988\n",
      "F1 Score: 0.75594472293634\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.174182  [    0/10977]\n",
      "loss: 0.082160  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.204254 \n",
      "\n",
      "Precision: 0.7028347927386629\n",
      "Recall: 0.7980022108989766\n",
      "F1 Score: 0.7473962597690476\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.121921  [    0/10977]\n",
      "loss: 0.094557  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.138194 \n",
      "\n",
      "Precision: 0.5085227243833936\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.6726749598267112\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.106507  [    0/10977]\n",
      "loss: 0.041780  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.159316 \n",
      "\n",
      "Precision: 0.4909687986263339\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.6576202047466655\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.080915  [    0/10977]\n",
      "loss: 0.148807  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Avg loss: 0.164558 \n",
      "\n",
      "Precision: 0.488515403425684\n",
      "Recall: 0.9678135297689953\n",
      "F1 Score: 0.6492881652196199\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.085863  [    0/10977]\n",
      "loss: 0.169729  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.128359 \n",
      "\n",
      "Precision: 0.5452322705059153\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.7031881614916706\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.105660  [    0/10977]\n",
      "loss: 0.221264  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.102749 \n",
      "\n",
      "Precision: 0.6031207557454494\n",
      "Recall: 0.9866814540878862\n",
      "F1 Score: 0.7486268637122739\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.115323  [    0/10977]\n",
      "loss: 0.079630  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.140880 \n",
      "\n",
      "Precision: 0.5090702918986945\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6739167200435144\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.038245  [    0/10977]\n",
      "loss: 0.067214  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.212765 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.40688717531994933\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.5778594570394209\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.059537  [    0/10977]\n",
      "loss: 0.029354  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.091459 \n",
      "\n",
      "Precision: 0.6520467788593072\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.7862446539996136\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.136039  [    0/10977]\n",
      "loss: 0.079289  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.7%, Avg loss: 0.189596 \n",
      "\n",
      "Precision: 0.42088014784232136\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.5920274330986015\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.122634  [    0/10977]\n",
      "loss: 0.035139  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.272850 \n",
      "\n",
      "Precision: 0.34548944205186394\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.5134017686125395\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.103987  [    0/10977]\n",
      "loss: 0.126987  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.460652 \n",
      "\n",
      "Precision: 0.2556155807346728\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.40696823154040823\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.144485  [    0/10977]\n",
      "loss: 0.026686  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.162808 \n",
      "\n",
      "Precision: 0.46991103888063296\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6386869634221974\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.084358  [    0/10977]\n",
      "loss: 0.094569  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.167127 \n",
      "\n",
      "Precision: 0.4728232165022522\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.6409112210797586\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.306692  [    0/10977]\n",
      "loss: 0.078641  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 81.0%, Avg loss: 0.314066 \n",
      "\n",
      "Precision: 0.3011077532691918\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.4623675658248598\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.077712  [    0/10977]\n",
      "loss: 0.073477  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.106393 \n",
      "\n",
      "Precision: 0.6255289095519823\n",
      "Recall: 0.9844616982856638\n",
      "F1 Score: 0.7649801492328662\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.127288  [    0/10977]\n",
      "loss: 0.037784  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Avg loss: 0.100004 \n",
      "\n",
      "Precision: 0.6273817880918716\n",
      "Recall: 0.9866814540878862\n",
      "F1 Score: 0.7670357933779632\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.100724  [    0/10977]\n",
      "loss: 0.270549  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.211812 \n",
      "\n",
      "Precision: 0.3978685595121289\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.5683435198583365\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.161599  [    0/10977]\n",
      "loss: 0.073182  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.4%, Avg loss: 0.126586 \n",
      "\n",
      "Precision: 0.5533621187331146\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.7113356080902874\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.060541  [    0/10977]\n",
      "loss: 0.117633  [ 6400/10977]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     train(train_dataloader, model, loss_fn, optimizer)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[165], line 10\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m---> 10\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\n\u001b[1;32m     13\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(train_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(test_diagnostic) - sum(test_diagnostic)) / len(test_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b5287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
