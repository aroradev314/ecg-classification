{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7693ea89",
   "metadata": {},
   "source": [
    "# Electrolet:  \n",
    "A Machine Learning Algorithm to Diagnose ECG Arrhythmias Based On the Continuous Wavelet Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b40fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras import backend as K\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import funcs\n",
    "from sklearn.decomposition import PCA\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import Input, Dense\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81dd33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pickled/\"\n",
    "trainReadings = funcs.unpickler(path + 'train_readings.pkl')\n",
    "trainDiagnostic = funcs.unpickler(path + 'train_diagnostic.pkl')\n",
    "validateReadings = funcs.unpickler(path + 'validate_readings.pkl')\n",
    "validateDiagnostic = funcs.unpickler(path + 'validate_diagnostic.pkl')\n",
    "testReadings = funcs.unpickler(path + 'test_readings.pkl')\n",
    "testDiagnostic = funcs.unpickler(path + 'test_diagnostic.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4026862f",
   "metadata": {},
   "source": [
    "# Neural network that applies CWT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3da9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "normalizedTrain = scaler.fit_transform(trainReadings)\n",
    "normalizedTest = scaler.transform(testReadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2815309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransform = scaler.fit_transform(funcs.easy_cwt(normalizedTrain, [0.8], 'mexh'))\n",
    "testTransform = scaler.transform(funcs.easy_cwt(normalizedTest, [0.8], 'mexh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de9dba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the standard deviation of the distance between neighboring peaks in the CWT coefficients\n",
    "\n",
    "trainDeviations = []\n",
    "for i in trainTransform:\n",
    "    highest = np.mean(np.array(sorted(i)[-4:-2]))\n",
    "    peaks = sorted(find_peaks(i, height=highest / 2, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        trainDeviations.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        trainDeviations.append(-1)\n",
    "        \n",
    "testDeviations = []\n",
    "for i in testTransform:\n",
    "    highest = np.mean(np.array(sorted(i)[-2]))\n",
    "    peaks = sorted(find_peaks(i, height=highest / 2, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        testDeviations.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        testDeviations.append(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4da414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average standard deviation of length between peaks for sinus rhythm: 3.7074495579036832\n",
      "Average standard deviation of length between peaks for atrial fibrillation: 19.429383041849555\n"
     ]
    }
   ],
   "source": [
    "zeros = 0\n",
    "totalZero = 0\n",
    "ones = 0\n",
    "totalOne = 0\n",
    "for i in range(len(trainDiagnostic)):\n",
    "    if trainDeviations[i] != -1:  # no nan values\n",
    "        if trainDiagnostic[i] == 0:\n",
    "            zeros += 1\n",
    "            totalZero += trainDeviations[i]\n",
    "        else:\n",
    "            ones += 1\n",
    "            totalOne += trainDeviations[i]\n",
    "        \n",
    "print(\"Average standard deviation of length between peaks for sinus rhythm: \" + str(totalZero / zeros))\n",
    "print(\"Average standard deviation of length between peaks for atrial fibrillation: \" + str(totalOne / ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eb1c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in trainReadings:\n",
    "    highest = np.mean(np.array(sorted(i)[-7]))\n",
    "    peaks = sorted(find_peaks(i, height=highest, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        a.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        a.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d550b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "bump = 10\n",
    "slideTrainTransform, slideTrainDiagnostic = funcs.make_windows(trainTransform, trainDiagnostic, 500, bump)\n",
    "slideTestTransform, slideTestDiagnostic = funcs.make_windows(testTransform, testDiagnostic, 500, bump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98ac6169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA represents 74.6260662690086% of the original variance\n"
     ]
    }
   ],
   "source": [
    "components = 150\n",
    "pca = PCA(n_components = components) \n",
    "pca.fit(slideTrainTransform)\n",
    "print(\"PCA represents \" + str(sum(pca.explained_variance_ratio_) * 100) + \"% of the original variance\")\n",
    "\n",
    "trainComponents = pca.transform(slideTrainTransform).tolist()\n",
    "testComponents = pca.transform(slideTestTransform).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52229465",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowsPerOriginal = len(slideTrainTransform) / len(trainTransform)\n",
    "for i in range(len(trainComponents)):\n",
    "    trainComponents[i].append(trainDeviations[int(i / windowsPerOriginal)])\n",
    "    \n",
    "    \n",
    "for i in range(len(testComponents)):\n",
    "    testComponents[i].append(testDeviations[int(i / windowsPerOriginal)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c63ec4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainComponents = np.array(trainComponents)\n",
    "testComponents = np.array(testComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9804586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_model(activation, shape):\n",
    "    inputs = Input(shape=shape)\n",
    "    hidden1 = Dense(20, activation=tf.nn.relu)(inputs)  # amount of neurons in hidden layer is mean between\n",
    "    # first and last layer\n",
    "    hidden2 = Dense(20, activation=tf.nn.relu)(hidden1)\n",
    "    hidden3 = Dense(20, activation=tf.nn.relu)(hidden2)\n",
    "    hidden4 = Dense(20, activation=tf.nn.relu)(hidden3)\n",
    "    outputs = Dense(1, activation=activation)(hidden4)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b1f55ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5447102024612942, 1: 6.091564927857935}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(trainDiagnostic),\n",
    "                                        y = trainDiagnostic                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(trainDiagnostic), class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95842c81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelv3 = basic_model('sigmoid', components + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a7d57e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelv3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy', tf.keras.metrics.FalseNegatives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b86ba6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb791325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17495/17495 [==============================] - 21s 1ms/step - loss: 0.2127 - accuracy: 0.9034 - false_negatives_2: 1507.0000\n",
      "Epoch 2/100\n",
      "17495/17495 [==============================] - 23s 1ms/step - loss: 0.1961 - accuracy: 0.9079 - false_negatives_2: 1227.0000\n",
      "Epoch 3/100\n",
      "17495/17495 [==============================] - 22s 1ms/step - loss: 0.1941 - accuracy: 0.9088 - false_negatives_2: 1179.0000\n",
      "Epoch 4/100\n",
      "17495/17495 [==============================] - 23s 1ms/step - loss: 0.1925 - accuracy: 0.9081 - false_negatives_2: 1125.0000\n",
      "Epoch 5/100\n",
      "17495/17495 [==============================] - 22s 1ms/step - loss: 0.1914 - accuracy: 0.9082 - false_negatives_2: 1092.0000\n",
      "Epoch 6/100\n",
      "17495/17495 [==============================] - 20s 1ms/step - loss: 0.1903 - accuracy: 0.9081 - false_negatives_2: 1039.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8958b5ad30>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv3.fit(trainComponents, slideTrainDiagnostic, epochs=100, class_weight=class_weights, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43cae6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5834/5834 [==============================] - 4s 684us/step - loss: 0.2846 - accuracy: 0.9017 - false_negatives_2: 534.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28460830450057983, 0.9017411470413208, 534.0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelv3.evaluate(testComponents, slideTestDiagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6da981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17495/17495 [==============================] - 9s 537us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    513876\n",
      "           1       0.47      0.98      0.63     45951\n",
      "\n",
      "    accuracy                           0.91    559827\n",
      "   macro avg       0.73      0.94      0.79    559827\n",
      "weighted avg       0.95      0.91      0.92    559827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "funcs.evaluate_model(modelv3.predict(trainComponents), slideTrainDiagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5952ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5834/5834 [==============================] - 4s 616us/step\n"
     ]
    }
   ],
   "source": [
    "windowsPerOriginal = int(len(slideTrainTransform) / len(trainTransform))\n",
    "\n",
    "predicted = modelv3.predict(testComponents)\n",
    "\n",
    "slideToRegLabels = []\n",
    "for i in range(0, len(predicted), windowsPerOriginal):\n",
    "    current = 0\n",
    "    for j in range(i, i + windowsPerOriginal):\n",
    "        current += predicted[j]\n",
    "    if current >= windowsPerOriginal / 1.2:\n",
    "        slideToRegLabels.append(1)\n",
    "    else:\n",
    "        slideToRegLabels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc55a292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      3353\n",
      "           1       0.51      0.91      0.65       307\n",
      "\n",
      "    accuracy                           0.92      3660\n",
      "   macro avg       0.75      0.92      0.80      3660\n",
      "weighted avg       0.95      0.92      0.93      3660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "funcs.evaluate_model(slideToRegLabels, testDiagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03071659",
   "metadata": {},
   "source": [
    "# Neural network that doesn't apply CWT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b02edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDeviations_ = []\n",
    "for i in normalizedTrain:\n",
    "    highest = np.mean(np.array(sorted(i)[-4:-2]))\n",
    "    peaks = sorted(find_peaks(i, height=highest / 2, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        trainDeviations_.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        trainDeviations_.append(-1)\n",
    "        \n",
    "testDeviations_ = []\n",
    "for i in normalizedTest:\n",
    "    highest = np.mean(np.array(sorted(i)[-2]))\n",
    "    peaks = sorted(find_peaks(i, height=highest / 2, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        testDeviations_.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        testDeviations_.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29089b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0\n",
    "totalZero = 0\n",
    "ones = 0\n",
    "totalOne = 0\n",
    "for i in range(len(trainDiagnostic)):\n",
    "    if trainDeviations[i] != -1:  # no nan values\n",
    "        if trainDiagnostic[i] == 0:\n",
    "            zeros += 1\n",
    "            totalZero += trainDeviations[i]\n",
    "        else:\n",
    "            ones += 1\n",
    "            totalOne += trainDeviations[i]\n",
    "        \n",
    "print(\"Average standard deviation of length between peaks for sinus rhythm: \" + str(totalZero / zeros))\n",
    "print(\"Average standard deviation of length between peaks for atrial fibrillation: \" + str(totalOne / ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ = []\n",
    "for i in trainReadings:\n",
    "    highest = np.mean(np.array(sorted(i)[-7]))\n",
    "    peaks = sorted(find_peaks(i, height=highest, distance=50)[0])\n",
    "    differences = []\n",
    "    for j in range(1, len(peaks)):\n",
    "        differences.append(peaks[j] - peaks[j - 1])\n",
    "    if len(differences) > 0:\n",
    "        a_.append(np.std(np.array(differences)))\n",
    "    else:\n",
    "        a_.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f325aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelv4 = basic_model('sigmoid', components + 1)\n",
    "modelv4.fit(a, trainDiagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs.evaluate_model(aTest, testDiagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfa5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook models.ipynb to html\n",
      "[NbConvertApp] Writing 631898 bytes to models.html\n"
     ]
    }
   ],
   "source": [
    " !jupyter nbconvert --to html models.ipynb  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e8b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG Classification",
   "language": "python",
   "name": "ecg-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
