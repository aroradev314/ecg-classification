{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d25b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pywt\n",
    "import torchsummary\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2359e6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e57a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickler(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "    return a\n",
    "\n",
    "path = \"pickled/\"\n",
    "train_readings = unpickler(path + 'train_readings.pkl')\n",
    "train_diagnostic = unpickler(path + 'train_diagnostic.pkl').astype('float32')\n",
    "validate_readings = unpickler(path + 'validate_readings.pkl')\n",
    "validate_diagnostic = unpickler(path + 'validate_diagnostic.pkl').astype('float32')\n",
    "test_readings = unpickler(path + 'test_readings.pkl')\n",
    "test_diagnostic = unpickler(path + 'test_diagnostic.pkl').astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2864058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECG(Dataset):\n",
    "    def __init__(self, readings, labels, cwt=False, scales=[], wavelet=''):\n",
    "        self.readings = readings # should i convert to torch.tensor here?\n",
    "        self.labels = labels\n",
    "        self.scales = scales\n",
    "        self.wavelet = wavelet\n",
    "        if cwt:\n",
    "            self.apply_cwt()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.readings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.readings[idx], self.labels[idx]\n",
    "    \n",
    "    def apply_cwt(self):\n",
    "        cwt = lambda x : pywt.cwt(x, self.scales, self.wavelet)[0] #pytorch uses channels first, unlike tensorflow's default\n",
    "        self.readings = np.array([cwt(i) for i in self.readings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4479b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scales = 10\n",
    "scales = np.linspace(0.1, 4, total_scales) # 10 evenly spaced numbers between 0.1 and 4\n",
    "wavelet = 'mexh'\n",
    "batch_size = 64\n",
    "kernel_size = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462bdcee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how to increase efficiency?\n",
    "\n",
    "train_dataloader = DataLoader(ECG(train_readings, \n",
    "                                  train_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)\n",
    "validate_dataloader = DataLoader(ECG(validate_readings, \n",
    "                                  validate_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(ECG(test_readings, \n",
    "                                  test_diagnostic, \n",
    "                                  cwt=True, scales=scales, wavelet=wavelet), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25ce9b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 10, 1000])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d81daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best way to adjust hyperparameters\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        modules = []\n",
    "        modules.append(\n",
    "            nn.Conv1d(in_channels=total_scales, out_channels=32, kernel_size=kernel_size, padding='same')) \n",
    "        modules.append(\n",
    "            nn.BatchNorm1d(num_features=32))\n",
    "        modules.append(\n",
    "            nn.Dropout(0.2)) # 20 percent of the inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool1d(kernel_size=kernel_size * 2))  \n",
    "        \n",
    "        modules.append(\n",
    "            nn.Conv1d(in_channels=32, out_channels=32, kernel_size=6, padding='same')) \n",
    "        modules.append(\n",
    "            nn.BatchNorm1d(num_features=32))\n",
    "        modules.append(\n",
    "            nn.Dropout(0.2)) # 20 percent of the inputs are randomly dropped\n",
    "        modules.append(\n",
    "            nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.MaxPool1d(kernel_size=4)) \n",
    "        \n",
    "        modules.append(nn.Flatten())\n",
    "        modules.append(nn.Linear(96, 256)) # dense layer with 50 neurons \n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(\n",
    "            nn.Linear(256, 2))\n",
    "        modules.append(\n",
    "            nn.LogSoftmax(dim=1))\n",
    "    \n",
    "        self.network = nn.Sequential(*modules) # unpack the modules\n",
    "    \n",
    "    def summary(self):\n",
    "        return torchsummary.summary(self, input_size=(total_scales, 1000))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        prob = self.network(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46231b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-5\n",
    "def get_precision(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 1:\n",
    "            if y_true[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    \n",
    "    return tp / (tp + fp + EPS)\n",
    "\n",
    "def get_recall(y_pred, y_true):\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] == 1:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    return tp / (tp + fn + EPS)\n",
    "        \n",
    "\n",
    "def get_f1(_precision, _recall):\n",
    "    return (2 * _precision * _recall) / (_precision + _recall + EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2903e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.path.join(os.getcwd(), 'torch_check')\n",
    "best_f1_file = os.path.join(current_directory, 'max_f1.txt')\n",
    "\n",
    "def get_max_f1():\n",
    "    max_f1_score = open(os.path.join(current_directory, 'max_f1.txt'), 'r').readline().strip(\"\\n\")\n",
    "    return float(max_f1_score)\n",
    "\n",
    "def update_f1(new_f1):\n",
    "    with open(best_f1_file, 'w') as file:\n",
    "        file.write(str(new_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd58a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.type(torch.FloatTensor).to(device)\n",
    "        y = y.type(torch.LongTensor).to(device)\n",
    "    \n",
    "        # Compute prediction error\n",
    "        pred = model(X).to(device)\n",
    "        loss = loss_fn(pred, y).to(device)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "963e8619",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1_model = CNN().to(device)\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    total_true = torch.empty(0).to(device)\n",
    "    total_pred = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.type(torch.FloatTensor).to(device)\n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            pred = model(X).to(device)\n",
    "            \n",
    "            round_pred = torch.argmax(pred, dim=1).to(device)\n",
    "            \n",
    "            total_true = torch.cat((total_true, y)).to(device)\n",
    "            \n",
    "            total_pred = torch.cat((total_pred, round_pred)).to(device)\n",
    "            \n",
    "            test_loss += loss_fn(pred, y).to(device).item()\n",
    "            correct += (round_pred == y).type(torch.float).sum().item()\n",
    "        \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    precision = get_precision(total_pred, total_true)\n",
    "    recall = get_recall(total_pred, total_true)\n",
    "    f1 = get_f1(precision, recall)\n",
    "    \n",
    "    max_f1 = get_max_f1()\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        update_f1(max_f1)\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(current_directory, f'Loss:{test_loss:.2f}|F1:{f1:.2f}.pt'))\n",
    "    \n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c78d47af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9295104085893039"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_max_f1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7563a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the negative class: 1.0\n",
      "Weight of the positive class: 7.0\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(train_diagnostic),\n",
    "                                        y = train_diagnostic                                                    \n",
    "                                    )\n",
    "class_weights = torch.ceil(torch.from_numpy(class_weights)).type(torch.FloatTensor).to(device)\n",
    "print(f\"Weight of the negative class: {class_weights[0].item()}\")\n",
    "print(f\"Weight of the positive class: {class_weights[1].item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6812d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.815523  [    0/10977]\n",
      "loss: 0.311570  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.301904 \n",
      "\n",
      "Precision: 0.3744228976250097\n",
      "Recall: 0.9001109778012101\n",
      "F1 Score: 0.5288514063585396\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.259188  [    0/10977]\n",
      "loss: 0.263769  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.314348 \n",
      "\n",
      "Precision: 0.3250186138309061\n",
      "Recall: 0.9689234076701065\n",
      "F1 Score: 0.486753971764647\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.258399  [    0/10977]\n",
      "loss: 0.175477  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.8%, Avg loss: 0.245032 \n",
      "\n",
      "Precision: 0.3825937079595273\n",
      "Recall: 0.9855715761867749\n",
      "F1 Score: 0.5512063960841037\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.196269  [    0/10977]\n",
      "loss: 0.215822  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.210043 \n",
      "\n",
      "Precision: 0.49999999713958815\n",
      "Recall: 0.9700332855712177\n",
      "F1 Score: 0.6598671559064959\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.145456  [    0/10977]\n",
      "loss: 0.228560  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.194752 \n",
      "\n",
      "Precision: 0.6409638502733828\n",
      "Recall: 0.885682565086764\n",
      "F1 Score: 0.7437043480462456\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.137119  [    0/10977]\n",
      "loss: 0.352981  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.0%, Avg loss: 0.232846 \n",
      "\n",
      "Precision: 0.5066751398177042\n",
      "Recall: 0.8845726871856527\n",
      "F1 Score: 0.6442960912918285\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.317658  [    0/10977]\n",
      "loss: 0.141029  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.151423 \n",
      "\n",
      "Precision: 0.5511860140375405\n",
      "Recall: 0.9800221866812189\n",
      "F1 Score: 0.7055487225682344\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.078399  [    0/10977]\n",
      "loss: 0.319550  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.1%, Avg loss: 0.185192 \n",
      "\n",
      "Precision: 0.5097926237915171\n",
      "Recall: 0.9822419424834413\n",
      "F1 Score: 0.6712127886459286\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.171517  [    0/10977]\n",
      "loss: 0.164162  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.208846 \n",
      "\n",
      "Precision: 0.7110481519258909\n",
      "Recall: 0.8357380595367585\n",
      "F1 Score: 0.7683623716220768\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.127860  [    0/10977]\n",
      "loss: 0.069613  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.9%, Avg loss: 0.229089 \n",
      "\n",
      "Precision: 0.384648740743067\n",
      "Recall: 0.9844616982856638\n",
      "F1 Score: 0.5531609079242084\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.360154  [    0/10977]\n",
      "loss: 0.309191  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.203598 \n",
      "\n",
      "Precision: 0.6085603065481688\n",
      "Recall: 0.8679245186689842\n",
      "F1 Score: 0.7154571788820013\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.065696  [    0/10977]\n",
      "loss: 0.049414  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.188939 \n",
      "\n",
      "Precision: 0.5220318205506008\n",
      "Recall: 0.9467258496478819\n",
      "F1 Score: 0.6729737165132609\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.115866  [    0/10977]\n",
      "loss: 0.201011  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.7%, Avg loss: 0.167904 \n",
      "\n",
      "Precision: 0.4685863849812231\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.6367797023250196\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.247776  [    0/10977]\n",
      "loss: 0.055427  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Avg loss: 0.164274 \n",
      "\n",
      "Precision: 0.5233253557217383\n",
      "Recall: 0.971143163472329\n",
      "F1 Score: 0.6801353581916487\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.163623  [    0/10977]\n",
      "loss: 0.049152  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.0%, Avg loss: 0.216820 \n",
      "\n",
      "Precision: 0.3863049078970503\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.5566202316196993\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.110438  [    0/10977]\n",
      "loss: 0.373000  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.179347 \n",
      "\n",
      "Precision: 0.5470704374781407\n",
      "Recall: 0.9223085358234347\n",
      "F1 Score: 0.6867721799341324\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.306529  [    0/10977]\n",
      "loss: 0.175281  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.162493 \n",
      "\n",
      "Precision: 0.5447352370983857\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.7036117720466408\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.139033  [    0/10977]\n",
      "loss: 0.102221  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.142123 \n",
      "\n",
      "Precision: 0.6727999946176001\n",
      "Recall: 0.9334073148345471\n",
      "F1 Score: 0.7819570025813138\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.110486  [    0/10977]\n",
      "loss: 0.462955  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 74.5%, Avg loss: 0.386818 \n",
      "\n",
      "Precision: 0.24309691325637\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.39085647567134063\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.405173  [    0/10977]\n",
      "loss: 0.243496  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.2%, Avg loss: 0.213011 \n",
      "\n",
      "Precision: 0.3906590991241418\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.5607728870145062\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.193735  [    0/10977]\n",
      "loss: 0.094827  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.8%, Avg loss: 0.192224 \n",
      "\n",
      "Precision: 0.4224952721054098\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.5926375040596299\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.337939  [    0/10977]\n",
      "loss: 0.250350  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.126380 \n",
      "\n",
      "Precision: 0.6401459807288614\n",
      "Recall: 0.9733629192745514\n",
      "F1 Score: 0.7723421901817169\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.175049  [    0/10977]\n",
      "loss: 0.075584  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Avg loss: 0.132193 \n",
      "\n",
      "Precision: 0.6041379268680143\n",
      "Recall: 0.9722530413734402\n",
      "F1 Score: 0.7452100685547214\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.119241  [    0/10977]\n",
      "loss: 0.057095  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.114604 \n",
      "\n",
      "Precision: 0.6631178656797121\n",
      "Recall: 0.9678135297689953\n",
      "F1 Score: 0.7869987775493288\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.065366  [    0/10977]\n",
      "loss: 0.120048  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.0%, Avg loss: 0.299115 \n",
      "\n",
      "Precision: 0.6025862017018431\n",
      "Recall: 0.7758046528767519\n",
      "F1 Score: 0.6783065716867096\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.127353  [    0/10977]\n",
      "loss: 0.149856  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.0%, Avg loss: 0.210220 \n",
      "\n",
      "Precision: 0.40598096780253295\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.576572455760767\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.194999  [    0/10977]\n",
      "loss: 0.039703  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.0%, Avg loss: 0.115834 \n",
      "\n",
      "Precision: 0.6224703375961596\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.7643482952392077\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.246200  [    0/10977]\n",
      "loss: 0.083247  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 87.6%, Avg loss: 0.204354 \n",
      "\n",
      "Precision: 0.396712570427754\n",
      "Recall: 0.9911209656923311\n",
      "F1 Score: 0.5666202791185837\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.035499  [    0/10977]\n",
      "loss: 0.153206  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.220861 \n",
      "\n",
      "Precision: 0.3756281391305354\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.545450564197998\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.099642  [    0/10977]\n",
      "loss: 0.095832  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.233914 \n",
      "\n",
      "Precision: 0.3464658155795063\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.5140362813677614\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.074135  [    0/10977]\n",
      "loss: 0.074681  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.248342 \n",
      "\n",
      "Precision: 0.3626107962827929\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.5320682142335499\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.036887  [    0/10977]\n",
      "loss: 0.041674  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.161388 \n",
      "\n",
      "Precision: 0.46008188096170993\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.6297680050302197\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.067850  [    0/10977]\n",
      "loss: 0.048372  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 83.2%, Avg loss: 0.257457 \n",
      "\n",
      "Precision: 0.3275109158387521\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.49328211007953565\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.184556  [    0/10977]\n",
      "loss: 0.122839  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 88.4%, Avg loss: 0.197227 \n",
      "\n",
      "Precision: 0.41347484811502144\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.5840897198376613\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.112977  [    0/10977]\n",
      "loss: 0.078214  [ 6400/10977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.138782 \n",
      "\n",
      "Precision: 0.6262848705852799\n",
      "Recall: 0.9467258496478819\n",
      "F1 Score: 0.7538617496895743\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.038163  [    0/10977]\n",
      "loss: 0.017963  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Avg loss: 0.092894 \n",
      "\n",
      "Precision: 0.6432664710367731\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.781884646403009\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.020755  [    0/10977]\n",
      "loss: 0.135034  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.118017 \n",
      "\n",
      "Precision: 0.5730843491752456\n",
      "Recall: 0.9877913319889975\n",
      "F1 Score: 0.7253417203387075\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.070215  [    0/10977]\n",
      "loss: 0.076777  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.4%, Avg loss: 0.161862 \n",
      "\n",
      "Precision: 0.4607490997396147\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6301711102912776\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.163502  [    0/10977]\n",
      "loss: 0.140546  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Avg loss: 0.128651 \n",
      "\n",
      "Precision: 0.5372596121558918\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.6970714604160826\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.145368  [    0/10977]\n",
      "loss: 0.070349  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Avg loss: 0.165364 \n",
      "\n",
      "Precision: 0.48540540278159244\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6528490981046208\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.092103  [    0/10977]\n",
      "loss: 0.108775  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.8%, Avg loss: 0.181312 \n",
      "\n",
      "Precision: 0.469795035222249\n",
      "Recall: 0.966703651867884\n",
      "F1 Score: 0.6323004939130642\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.243740  [    0/10977]\n",
      "loss: 0.036291  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.3%, Avg loss: 0.117731 \n",
      "\n",
      "Precision: 0.5943204827970218\n",
      "Recall: 0.9755826750767739\n",
      "F1 Score: 0.7386507509056099\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.052709  [    0/10977]\n",
      "loss: 0.140296  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.109820 \n",
      "\n",
      "Precision: 0.5946308684924103\n",
      "Recall: 0.9833518203845525\n",
      "F1 Score: 0.7411078024765817\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.025626  [    0/10977]\n",
      "loss: 0.059309  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.429496 \n",
      "\n",
      "Precision: 0.22310361868343176\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.3647386550758428\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.074315  [    0/10977]\n",
      "loss: 0.115959  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.0%, Avg loss: 0.126133 \n",
      "\n",
      "Precision: 0.5410627986650798\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.7008167053953274\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.060335  [    0/10977]\n",
      "loss: 0.062502  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.8%, Avg loss: 0.135739 \n",
      "\n",
      "Precision: 0.5008356518059295\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.6669094914704632\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.021174  [    0/10977]\n",
      "loss: 0.531865  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.091441 \n",
      "\n",
      "Precision: 0.6795069285091916\n",
      "Recall: 0.9789123087801076\n",
      "F1 Score: 0.8021779660689586\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.052402  [    0/10977]\n",
      "loss: 0.069972  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.8%, Avg loss: 0.113260 \n",
      "\n",
      "Precision: 0.5697008238720508\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.7241053938350759\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.125895  [    0/10977]\n",
      "loss: 0.161752  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.5%, Avg loss: 0.161236 \n",
      "\n",
      "Precision: 0.43804877835098155\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6086030056881152\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.099967  [    0/10977]\n",
      "loss: 0.051091  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.086995 \n",
      "\n",
      "Precision: 0.6793602385425724\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.8057765570418914\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.059310  [    0/10977]\n",
      "loss: 0.141369  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Avg loss: 0.143539 \n",
      "\n",
      "Precision: 0.4807897519701721\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.649364979428031\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.049860  [    0/10977]\n",
      "loss: 0.061420  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Avg loss: 0.099052 \n",
      "\n",
      "Precision: 0.6573116642739169\n",
      "Recall: 0.9877913319889975\n",
      "F1 Score: 0.7893521792849189\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.070439  [    0/10977]\n",
      "loss: 0.154215  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.120009 \n",
      "\n",
      "Precision: 0.5503685469879082\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.7085758741954122\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.127688  [    0/10977]\n",
      "loss: 0.073681  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Avg loss: 0.155021 \n",
      "\n",
      "Precision: 0.4665282798830914\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.6357806607266724\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.051880  [    0/10977]\n",
      "loss: 0.116070  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Avg loss: 0.084688 \n",
      "\n",
      "Precision: 0.6691616716380114\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.7992799383204063\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.093755  [    0/10977]\n",
      "loss: 0.057972  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 91.5%, Avg loss: 0.136661 \n",
      "\n",
      "Precision: 0.4907002161340251\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.6573792291582531\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.111822  [    0/10977]\n",
      "loss: 0.025293  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.158614 \n",
      "\n",
      "Precision: 0.7417840305935772\n",
      "Recall: 0.8768035418778741\n",
      "F1 Score: 0.8036572850406465\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.101935  [    0/10977]\n",
      "loss: 0.026833  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.2%, Avg loss: 0.174103 \n",
      "\n",
      "Precision: 0.4326923056120562\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.6038199981591704\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.095851  [    0/10977]\n",
      "loss: 0.017286  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.231986 \n",
      "\n",
      "Precision: 0.3538884510844915\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.5227695618889941\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.032577  [    0/10977]\n",
      "loss: 0.058264  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.090333 \n",
      "\n",
      "Precision: 0.7472150750024416\n",
      "Recall: 0.9678135297689953\n",
      "F1 Score: 0.8433219604769115\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.035410  [    0/10977]\n",
      "loss: 0.043812  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Avg loss: 0.092548 \n",
      "\n",
      "Precision: 0.6170212723608698\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.7625058737588609\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.075464  [    0/10977]\n",
      "loss: 0.007941  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.077878 \n",
      "\n",
      "Precision: 0.7022961147878376\n",
      "Recall: 0.9844616982856638\n",
      "F1 Score: 0.8197733209097353\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.077112  [    0/10977]\n",
      "loss: 0.118785  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 82.1%, Avg loss: 0.285521 \n",
      "\n",
      "Precision: 0.3143555699812938\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.47821102126504156\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.091730  [    0/10977]\n",
      "loss: 0.217208  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.114006 \n",
      "\n",
      "Precision: 0.5445184703542189\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.7045408809018275\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.048001  [    0/10977]\n",
      "loss: 0.047484  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.103637 \n",
      "\n",
      "Precision: 0.6496350317544888\n",
      "Recall: 0.9877913319889975\n",
      "F1 Score: 0.7837908910932281\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.099559  [    0/10977]\n",
      "loss: 0.324125  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Avg loss: 0.129952 \n",
      "\n",
      "Precision: 0.5131428542106122\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.6774757038921294\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.119039  [    0/10977]\n",
      "loss: 0.060187  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 77.1%, Avg loss: 0.371484 \n",
      "\n",
      "Precision: 0.26360444627383134\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.41722290599129774\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.087441  [    0/10977]\n",
      "loss: 0.101041  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Avg loss: 0.156550 \n",
      "\n",
      "Precision: 0.44972486018146646\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.6199957125218516\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.074806  [    0/10977]\n",
      "loss: 0.063016  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.073381 \n",
      "\n",
      "Precision: 0.6916537813627992\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.8154849023112938\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.054273  [    0/10977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.087155  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.075902 \n",
      "\n",
      "Precision: 0.8038496718253926\n",
      "Recall: 0.9733629192745514\n",
      "F1 Score: 0.880517125028885\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.016950  [    0/10977]\n",
      "loss: 0.031747  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Avg loss: 0.109127 \n",
      "\n",
      "Precision: 0.5515970482088633\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.7101575270100424\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.027425  [    0/10977]\n",
      "loss: 0.065978  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.070421 \n",
      "\n",
      "Precision: 0.6981279196713891\n",
      "Recall: 0.9933407214945537\n",
      "F1 Score: 0.8199676597084924\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.104187  [    0/10977]\n",
      "loss: 0.044514  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.057268 \n",
      "\n",
      "Precision: 0.7273462724324735\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.841361516522753\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.011197  [    0/10977]\n",
      "loss: 0.035911  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Avg loss: 0.070770 \n",
      "\n",
      "Precision: 0.701095456172962\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.8223907364607446\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.126330  [    0/10977]\n",
      "loss: 0.131982  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.248763 \n",
      "\n",
      "Precision: 0.37541666510243055\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.5458912110551075\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.094487  [    0/10977]\n",
      "loss: 0.168000  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Avg loss: 0.080822 \n",
      "\n",
      "Precision: 0.632135302099117\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.7732711046925297\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.041490  [    0/10977]\n",
      "loss: 0.136323  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.109874 \n",
      "\n",
      "Precision: 0.586814617579539\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.7390006734659335\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.081074  [    0/10977]\n",
      "loss: 0.030827  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Avg loss: 0.077732 \n",
      "\n",
      "Precision: 0.6539868276957803\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.7883549925210536\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.100021  [    0/10977]\n",
      "loss: 0.046965  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.086065 \n",
      "\n",
      "Precision: 0.6632047428545642\n",
      "Recall: 0.9922308435934424\n",
      "F1 Score: 0.7950151993696157\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.041769  [    0/10977]\n",
      "loss: 0.121800  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.060256 \n",
      "\n",
      "Precision: 0.7514644288580382\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.8568653192338308\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.030137  [    0/10977]\n",
      "loss: 0.099788  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Avg loss: 0.073153 \n",
      "\n",
      "Precision: 0.6852559153150809\n",
      "Recall: 0.9955604772967761\n",
      "F1 Score: 0.8117598689789977\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.222760  [    0/10977]\n",
      "loss: 0.110518  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 93.6%, Avg loss: 0.107363 \n",
      "\n",
      "Precision: 0.5628140668164946\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.7188080538872953\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.020288  [    0/10977]\n",
      "loss: 0.072047  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.054320 \n",
      "\n",
      "Precision: 0.7756686732038941\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.8728106039630876\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.078418  [    0/10977]\n",
      "loss: 0.184048  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 81.2%, Avg loss: 0.275044 \n",
      "\n",
      "Precision: 0.3039811055871083\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.466231868450862\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.175146  [    0/10977]\n",
      "loss: 0.041892  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.067530 \n",
      "\n",
      "Precision: 0.7439330481679243\n",
      "Recall: 0.9866814540878862\n",
      "F1 Score: 0.8482775330565173\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.134165  [    0/10977]\n",
      "loss: 0.034407  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.087016 \n",
      "\n",
      "Precision: 0.6496722458144775\n",
      "Recall: 0.9900110877912199\n",
      "F1 Score: 0.7845158769685209\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.054539  [    0/10977]\n",
      "loss: 0.094844  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.059864 \n",
      "\n",
      "Precision: 0.7354627294392897\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.8463664535411115\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.120986  [    0/10977]\n",
      "loss: 0.078244  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.044155 \n",
      "\n",
      "Precision: 0.8072071999350703\n",
      "Recall: 0.9944505993956648\n",
      "F1 Score: 0.8910940009141707\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.013755  [    0/10977]\n",
      "loss: 0.036281  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.3%, Avg loss: 0.081727 \n",
      "\n",
      "Precision: 0.6362994305346086\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.7777250633829957\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.022145  [    0/10977]\n",
      "loss: 0.067487  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Avg loss: 0.092664 \n",
      "\n",
      "Precision: 0.5877364606148959\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.7403404419778208\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.050678  [    0/10977]\n",
      "loss: 0.024127  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.057432 \n",
      "\n",
      "Precision: 0.7788378076423434\n",
      "Recall: 0.9966703551978873\n",
      "F1 Score: 0.8743864981281955\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.065653  [    0/10977]\n",
      "loss: 0.011403  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.086829 \n",
      "\n",
      "Precision: 0.7171635719809543\n",
      "Recall: 0.9877913319889975\n",
      "F1 Score: 0.8309941845389904\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.087798  [    0/10977]\n",
      "loss: 0.043507  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.085264 \n",
      "\n",
      "Precision: 0.607142853051598\n",
      "Recall: 0.999999988901221\n",
      "F1 Score: 0.7555508480143388\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.060699  [    0/10977]\n",
      "loss: 0.024751  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Avg loss: 0.070089 \n",
      "\n",
      "Precision: 0.6615158155885518\n",
      "Recall: 0.9977802330989985\n",
      "F1 Score: 0.7955704195723176\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.048758  [    0/10977]\n",
      "loss: 0.025337  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Avg loss: 0.065948 \n",
      "\n",
      "Precision: 0.6777108382702497\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.8075321883831801\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.020560  [    0/10977]\n",
      "loss: 0.011095  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Avg loss: 0.128426 \n",
      "\n",
      "Precision: 0.5145797569206417\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.6792407899221343\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.039982  [    0/10977]\n",
      "loss: 0.049053  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 89.1%, Avg loss: 0.204119 \n",
      "\n",
      "Precision: 0.42877560538934917\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.599995793364982\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.114071  [    0/10977]\n",
      "loss: 0.045014  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Avg loss: 0.064722 \n",
      "\n",
      "Precision: 0.6880733892349129\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.8148435100531579\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.007393  [    0/10977]\n",
      "loss: 0.088675  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.046221 \n",
      "\n",
      "Precision: 0.7887817634637883\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.8814837969954674\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.038810  [    0/10977]\n",
      "loss: 0.021278  [ 6400/10977]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Avg loss: 0.090564 \n",
      "\n",
      "Precision: 0.6048387056126431\n",
      "Recall: 0.9988901110001098\n",
      "F1 Score: 0.7534486233395961\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "loss_fn = nn.NLLLoss(weight=class_weights).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(train_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ab431c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 1000]          13,152\n",
      "       BatchNorm1d-2             [-1, 32, 1000]              64\n",
      "           Dropout-3             [-1, 32, 1000]               0\n",
      "              ReLU-4             [-1, 32, 1000]               0\n",
      "         MaxPool1d-5               [-1, 32, 12]               0\n",
      "            Conv1d-6               [-1, 32, 12]           6,176\n",
      "       BatchNorm1d-7               [-1, 32, 12]              64\n",
      "           Dropout-8               [-1, 32, 12]               0\n",
      "              ReLU-9               [-1, 32, 12]               0\n",
      "        MaxPool1d-10                [-1, 32, 3]               0\n",
      "          Flatten-11                   [-1, 96]               0\n",
      "           Linear-12                  [-1, 256]          24,832\n",
      "             ReLU-13                  [-1, 256]               0\n",
      "           Linear-14                    [-1, 2]             514\n",
      "       LogSoftmax-15                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 44,802\n",
      "Trainable params: 44,802\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 1.00\n",
      "Params size (MB): 0.17\n",
      "Estimated Total Size (MB): 1.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac7df80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295104085893039\n"
     ]
    }
   ],
   "source": [
    "print(get_max_f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c762f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(best_model_directory)['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "658b1b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.242944 \n",
      "\n",
      "Precision: 0.8349514292895979\n",
      "Recall: 0.8403908521045326\n",
      "F1 Score: 0.8376573105480607\n"
     ]
    }
   ],
   "source": [
    "best_model = CNN().to(device)\n",
    "best_model.load_state_dict(state_dict)\n",
    "test(test_dataloader, best_model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "683184e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred = torch.empty(0).to(device)\n",
    "total_true = torch.empty(0).to(device)\n",
    "with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X = X.type(torch.FloatTensor).to(device)\n",
    "            pred = torch.exp(best_model(X))[:, 1].to(device) # convert log probabilities to probabilities\n",
    "            total_pred = torch.concat((total_pred, pred))\n",
    "            \n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            total_true = torch.concat((total_true, y))\n",
    "\n",
    "total_pred = np.array(total_pred.cpu())\n",
    "total_true = np.array(total_true.cpu())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33b4eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sci\n",
    "fpr, tpr, thresholds = sci.roc_curve(total_true, total_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f6e0a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = sci.precision_recall_curve(total_true, total_pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35f5b0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f06290fe4c0>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size = 8\n",
    "plt.figure(figsize=(size, size))\n",
    "recall = recall[::-1]\n",
    "precision = precision\n",
    "plt.plot(recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b55dfbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8351138082995048"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci.average_precision_score(total_true, total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18059865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model ROC Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "roc_score = sci.roc_auc_score(total_true, total_pred)\n",
    "print(f\"Best Model ROC Score: {roc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c932b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_accuracy(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    total_positive, predicted_positive, total_negative, predicted_negative = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.type(torch.FloatTensor).to(device)\n",
    "            y = y.type(torch.LongTensor).to(device)\n",
    "            \n",
    "            pred = model(X).to(device)\n",
    "            \n",
    "            round_pred = torch.argmax(pred, dim=1).to(device)\n",
    "            for i in range(len(y)):\n",
    "                if y[i] == 0:\n",
    "                    total_negative += 1\n",
    "                    if round_pred[i].item() == 0:\n",
    "                        predicted_negative += 1\n",
    "                else:\n",
    "                    total_positive += 1\n",
    "                    if round_pred[i].item() == 1:\n",
    "                        predicted_positive += 1\n",
    "\n",
    "    print(f\"Per class accuracy\")\n",
    "    print(f\"Sinus Rhythm: {(predicted_negative / total_negative):>0.1f}%\")\n",
    "    print(f\"Atrial fibrillation: {(predicted_positive / total_positive):>0.1f}%\")\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9e92b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9847897405308679\n",
      "0.8403908794788274\n",
      "Per class accuracy\n",
      "Sinus Rhythm: 1.0%\n",
      "Atrial fibrillation: 0.8%\n"
     ]
    }
   ],
   "source": [
    "per_class_accuracy(test_dataloader, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
